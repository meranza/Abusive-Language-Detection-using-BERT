# ðŸš¨ Abusive Language Detection using BERT

This project detects abusive comments on social media using **Natural Language Processing (NLP)** and a **BERT-based deep learning model**. It leverages pre-trained transformer embeddings to classify text into multiple categories of abuse with high accuracy.

---

## ðŸ§  Model Overview

- **Model**: DistilBERT (`distilbert-base-multilingual-cased`)
- **Framework**: PyTorch + HuggingFace Transformers
- **Dataset**: 143,000+ labeled comments (Kaggle Toxic Comment Classification)
- **Output Labels**:
  - `toxic`
  - `severe_toxic`
  - `obscene`
  - `threat`
  - `insult`
  - `identity_hate`

---

## ðŸ”§ Tech Stack

- Python
- PyTorch
- HuggingFace Transformers
- Flask (for web deployment)
- HTML/CSS (frontend)

---

## ðŸš€ How to Run

1. **Install dependencies**
   ```bash
   pip install flask torch transformers

2. **Run the Flask app**
   ```bash
   python app.py

## ðŸ“‚ Suggested Folder Structure
abusive-language-detection/
â”‚
â”œâ”€â”€ app.py                  # Flask backend using BERT
â”œâ”€â”€ model.pt                # Trained PyTorch model
â”œâ”€â”€ model.py                # Model architecture (DistilBERT + classifier)
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ index.html          # User input form
â”‚   â””â”€â”€ result.html         # Classification result display
â”œâ”€â”€ README.md
